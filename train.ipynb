{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.5/dist-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import os\n",
    "import sys\n",
    "import math\n",
    "\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = '0'\n",
    "sys.path.append(\"../\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from vae import VAE\n",
    "from config import FLAGS\n",
    "from batchloader import BatchLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train():\n",
    "    save_dir = \"model\"\n",
    "    \n",
    "    if not os.path.exists(save_dir):\n",
    "        os.makedirs(save_dir)\n",
    "    \n",
    "    tf.reset_default_graph()\n",
    "    \n",
    "    with tf.Session(config=tf.ConfigProto(log_device_placement=True)) as sess:\n",
    "        batchloader = BatchLoader()\n",
    "        with tf.variable_scope(\"VAE\"):\n",
    "            vae = VAE(sess=sess, batchloader=batchloader, learning_rate=FLAGS.LEARNING_RATE, training=True, ru=False)\n",
    "        \n",
    "        with tf.variable_scope(\"VAE\", reuse=True):\n",
    "            vae_test = VAE(sess=sess, batchloader=batchloader, learning_rate=FLAGS.LEARNING_RATE, training=False, ru=True)\n",
    "        \n",
    "        saver = tf.train.Saver()\n",
    "        #summary_writer = tf.summary.FileWriter(FLAGS.LOG_DIR, sess.graph)\n",
    "        \n",
    "        sess.run(tf.global_variables_initializer())\n",
    "        \n",
    "        loss_sum = []\n",
    "        reconst_loss_sum = []\n",
    "        kld_sum = []\n",
    "        \n",
    "        step = 0\n",
    "        lr = FLAGS.LEARNING_RATE\n",
    "        \n",
    "        train_batch = batchloader.make_batch(FLAGS.BATCH_SIZE, is_training=True)\n",
    "        total_batch = int(len(train_batch) / FLAGS.BATCH_SIZE)\n",
    "\n",
    "        val_batch_idx = 0\n",
    "        best_loss = 10000\n",
    "        patient = 0\n",
    "        exit = 0\n",
    "        \n",
    "        print(\"Start Learning!!\")\n",
    "        for epoch in range(FLAGS.EPOCH):\n",
    "                \n",
    "            for batch in range(total_batch):\n",
    "                step += 1\n",
    "                \n",
    "                kld_weight = (math.tanh((step-3500)/1000) + 1) / 2\n",
    "                \n",
    "                #print('batch: {}, batch_size: {}'.format(type(batch), type(FLAGS.BATCH_SIZE)))\n",
    "                batch_idx = batch*FLAGS.BATCH_SIZE\n",
    "                minibatch = train_batch[batch_idx:batch_idx+FLAGS.BATCH_SIZE]\n",
    "                encoder_input, decoder_input, target = batchloader.prepro_minibatch(minibatch, dropword=True)\n",
    "                #encoder_input, decoder_input, target = batchloader.next_batch(FLAGS.BATCH_SIZE, batch_idx=batch, is_training=True)\n",
    "                \n",
    "                #print('encoder_input: {}\\tdecoder_input: {}\\ttarget: {}\\tkld_weight: {}\\tstep: {}'.format(encoder_input, decoder_input, target, kld_weight, step))\n",
    "                feed_dict = {vae.encoder_input: encoder_input,\n",
    "                             vae.decoder_input: decoder_input,\n",
    "                             vae.target: target,\n",
    "                             vae.KL_d_weight: kld_weight,\n",
    "                             vae.step: step}\n",
    "                \n",
    "                #print('[type] encoder_input: {}\\tdecoder_input: {}\\ttarget: {}\\tKL_d_weight: {}\\tstep: {}'.format(type(encoder_input), type(decoder_input), type(target), type(kld_weight), type(step)))\n",
    "                encoder_length, decoder_length, en_input, logits, loss, reconst_loss, kld, _ = sess.run([vae.encoder_length, vae.decoder_length, vae.encoder_input, vae.logits, vae.loss, vae.reconst_loss, vae.KL_d, vae.train_op], \n",
    "                                                                              feed_dict=feed_dict)\n",
    "                \n",
    "                #print('[encoder_length] {}: {}\\t[decoder_length] {}: {}'.format(encoder_length, encoder_length.shape, decoder_length, decoder_length.shape))\n",
    "                \n",
    "                reconst_loss_sum.append(reconst_loss)\n",
    "                kld_sum.append(kld)\n",
    "                loss_sum.append(loss)\n",
    "                #summary_writer.add_summary(merged_summary, step)\n",
    "                \n",
    "                if batch%200 == 99:\n",
    "                    avg_loss = np.average(loss_sum)\n",
    "                    avg_reconst_loss = np.average(reconst_loss_sum)\n",
    "                    avg_kld = np.average(kld_sum)\n",
    "\n",
    "                    print('[Epoch {}] loss: {}, reconst_loss: {}, kld: {}'.format(epoch, avg_loss, avg_reconst_loss, avg_kld))\n",
    "                    loss_sum = []\n",
    "                    reconst_loss_sum = []\n",
    "                    kld_sum = []\n",
    "\n",
    "                    '''sample_train_input = sess.run([vae.encoder_input], feed_dict=feed_dict)\n",
    "                    print(sample_train_input, type(sample_train_input), np.shape(sample_train_input))\n",
    "                    encoder_input_texts = batchloader.logits2str(sample_train_input, 1, onehot=False)\n",
    "\n",
    "                    sample_train_outputs = batchloader.logits2str(logits, 1)\n",
    "\n",
    "\n",
    "                    print('train input: {}, train output: {}'.format(encoder_input_texts[0], sample_train_outputs[0]))'''\n",
    "                \n",
    "                \n",
    "            \n",
    "            \n",
    "            #validation output\n",
    "            val_batch = batchloader.make_batch(FLAGS.BATCH_SIZE, is_training=False)\n",
    "            #print('[val_batch] {}'.format(np.shape(val_batch)))\n",
    "            val_minibatch = val_batch[val_batch_idx*FLAGS.BATCH_SIZE:(val_batch_idx + 1)*FLAGS.BATCH_SIZE]\n",
    "            val_encoder_input, val_decoder_input, val_target = batchloader.prepro_minibatch(val_minibatch, dropword=False)\n",
    "            #print('[val encoder input] {}\\t[val decoder input] {}\\t[val target] {}'.format(val_encoder_input[0], val_decoder_input[0], val_target[0]))\n",
    "            #sample_input, _, sample_target = batchloader.next_batch(FLAGS.BATCH_SIZE, is_training=False)\n",
    "\n",
    "            val_logits, val_loss, val_prediction = sess.run([vae_test.logits, vae_test.reconst_loss, vae_test.decoder_prediction],\n",
    "                                                 feed_dict = {vae_test.encoder_input: val_encoder_input,\n",
    "                                                              vae_test.decoder_input: val_decoder_input,\n",
    "                                                              vae_test.target: val_target,\n",
    "                                                              vae_test.KL_d_weight: kld_weight})\n",
    "            \n",
    "            input_text = batchloader.input2str(val_encoder_input)\n",
    "            output_text = batchloader.pred2str(val_prediction)\n",
    "            \n",
    "            print('[input] {}\\n[output] {}'.format(input_text[0], output_text[0]))\n",
    "            \n",
    "            if val_loss < best_loss:\n",
    "                best_loss = val_loss\n",
    "                filename = os.path.join(save_dir, \"model_{}.ckpt\".format(epoch))\n",
    "                save_path = saver.save(sess, filename)\n",
    "                patient = 0\n",
    "            else:\n",
    "                if patient == 15:\n",
    "                    exit = 1\n",
    "                patient += 1\n",
    "\n",
    "            print('[Epoch {}] best loss: {}, current loss: {}, patient: {}'.format(epoch, best_loss, val_loss, patient))\n",
    "\n",
    "            #print('[val] logits[0]: {}, type(logit): {}, shape(logit): {}'.format(val_logits[0], type(val_logits), np.shape(val_logits)))\n",
    "            #val_input_texts = batchloader.logits2str(val_encoder_input, 1, onehot=False)\n",
    "            #val_output_texts = batchloader.logits2str(val_logits, 1)\n",
    "\n",
    "            #print('input length: {}\\toutput length: {}'.format(len(val_input_texts), len(val_output_texts)))\n",
    "            #for i in range(FLAGS.BATCH_SIZE):\n",
    "                #print('[VAL] input: {}\\toutput: {}'.format(val_input_texts[i], val_output_texts[i]))\n",
    "                \n",
    "            #print('sample input: {}, sample output: {}'.format(val_input_texts[0], val_output_texts[0]))\n",
    "            #summary_writer.add_summary(merged_summary, step)\n",
    "            \n",
    "            if exit == 1:\n",
    "                #save model\n",
    "                \n",
    "                print('Model saved in file {}'.format(save_path))\n",
    "                print(\"Finish Learning!!\")\n",
    "                break\n",
    "\n",
    "            val_batch_idx += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.001\n",
      "10002\n",
      "(32, 60, 353)\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.5/dist-packages/tensorflow/contrib/learn/python/learn/datasets/base.py:198: retry (from tensorflow.contrib.learn.python.learn.datasets.base) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use the retry module or similar alternatives.\n",
      "[decoder_input] (32, 60, 353)\n",
      "[latent] (32, 60, 13)\n",
      "[decoder_logit] (1920, 10002)\n",
      "[reconstruction_loss] (1920,)\n",
      "[reconst_loss] ()\n",
      "(32, 60, 353)\n",
      "[start] (32, 353)\n",
      "[reconstruction_loss] (60, 32)\n",
      "[reconst_loss] ()\n",
      "Start Learning!!\n",
      "[Epoch 0] loss: 501.04034423828125, reconst_loss: 500.8358459472656, kld: 203.59214782714844\n",
      "[Epoch 0] loss: 477.5327453613281, reconst_loss: 477.4717102050781, kld: 45.83076477050781\n",
      "[Epoch 0] loss: 459.8138427734375, reconst_loss: 459.7102355957031, kld: 50.5080680847168\n",
      "[Epoch 0] loss: 443.9869384765625, reconst_loss: 443.8168029785156, kld: 55.88475036621094\n",
      "[Epoch 0] loss: 429.9681396484375, reconst_loss: 429.73004150390625, kld: 52.77970886230469\n",
      "[Epoch 0] loss: 416.9253845214844, reconst_loss: 416.5958251953125, kld: 48.985862731933594\n",
      "[Epoch 0] loss: 403.61993408203125, reconst_loss: 403.1771240234375, kld: 44.298988342285156\n",
      "[input] consumers may want to move their telephones a little closer to the tv set\n",
      "[output] the is n't be a to the of\n",
      "[Epoch 0] best loss: 789.326416015625, current loss: 789.326416015625, patient: 0\n",
      "[Epoch 1] loss: 391.3980407714844, reconst_loss: 390.8619079589844, kld: 39.390769958496094\n",
      "[Epoch 1] loss: 379.5159912109375, reconst_loss: 378.85369873046875, kld: 35.74287033081055\n",
      "[Epoch 1] loss: 368.6925048828125, reconst_loss: 367.859130859375, kld: 30.435171127319336\n",
      "[Epoch 1] loss: 356.10369873046875, reconst_loss: 355.031982421875, kld: 26.58539581298828\n",
      "[Epoch 1] loss: 344.038818359375, reconst_loss: 342.6809387207031, kld: 23.046977996826172\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-4-379170c0a83f>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m     \u001b[0msys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margv\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m'ddd'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mFLAGS\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mLEARNING_RATE\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m     \u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-3-b66bed5be628>\u001b[0m in \u001b[0;36mtrain\u001b[0;34m()\u001b[0m\n\u001b[1;32m     58\u001b[0m                 \u001b[0;31m#print('[type] encoder_input: {}\\tdecoder_input: {}\\ttarget: {}\\tKL_d_weight: {}\\tstep: {}'.format(type(encoder_input), type(decoder_input), type(target), type(kld_weight), type(step)))\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     59\u001b[0m                 encoder_length, decoder_length, en_input, logits, loss, reconst_loss, kld, _ = sess.run([vae.encoder_length, vae.decoder_length, vae.encoder_input, vae.logits, vae.loss, vae.reconst_loss, vae.KL_d, vae.train_op], \n\u001b[0;32m---> 60\u001b[0;31m                                                                               feed_dict=feed_dict)\n\u001b[0m\u001b[1;32m     61\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     62\u001b[0m                 \u001b[0;31m#print('[encoder_length] {}: {}\\t[decoder_length] {}: {}'.format(encoder_length, encoder_length.shape, decoder_length, decoder_length.shape))\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    903\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    904\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[0;32m--> 905\u001b[0;31m                          run_metadata_ptr)\n\u001b[0m\u001b[1;32m    906\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    907\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run\u001b[0;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1138\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mfinal_fetches\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mfinal_targets\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mhandle\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mfeed_dict_tensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1139\u001b[0m       results = self._do_run(handle, final_targets, final_fetches,\n\u001b[0;32m-> 1140\u001b[0;31m                              feed_dict_tensor, options, run_metadata)\n\u001b[0m\u001b[1;32m   1141\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1142\u001b[0m       \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_run\u001b[0;34m(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1319\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mhandle\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1320\u001b[0m       return self._do_call(_run_fn, feeds, fetches, targets, options,\n\u001b[0;32m-> 1321\u001b[0;31m                            run_metadata)\n\u001b[0m\u001b[1;32m   1322\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1323\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_do_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_prun_fn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeeds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetches\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_call\u001b[0;34m(self, fn, *args)\u001b[0m\n\u001b[1;32m   1325\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_do_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1326\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1327\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1328\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mOpError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1329\u001b[0m       \u001b[0mmessage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcompat\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_text\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmessage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run_fn\u001b[0;34m(feed_dict, fetch_list, target_list, options, run_metadata)\u001b[0m\n\u001b[1;32m   1310\u001b[0m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_extend_graph\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1311\u001b[0m       return self._call_tf_sessionrun(\n\u001b[0;32m-> 1312\u001b[0;31m           options, feed_dict, fetch_list, target_list, run_metadata)\n\u001b[0m\u001b[1;32m   1313\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1314\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_prun_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_call_tf_sessionrun\u001b[0;34m(self, options, feed_dict, fetch_list, target_list, run_metadata)\u001b[0m\n\u001b[1;32m   1418\u001b[0m         return tf_session.TF_Run(\n\u001b[1;32m   1419\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptions\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_list\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1420\u001b[0;31m             status, run_metadata)\n\u001b[0m\u001b[1;32m   1421\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1422\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_call_tf_sessionprun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    sys.argv = ['ddd']\n",
    "    print(FLAGS.LEARNING_RATE)\n",
    "    train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
